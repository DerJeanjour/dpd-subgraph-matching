{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matching.glema.common.utils.io_utils as io_utils\n",
    "from matching.glema.common.utils.plot_utils import ColorScheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_prefix( filename ):\n",
    "    # Split the filename on underscores.\n",
    "    parts = filename.split( '_' )\n",
    "\n",
    "    prefix_parts = [ ]\n",
    "    for part in parts:\n",
    "        # If the part starts with a digit, assume it's the start of the timestamp.\n",
    "        if part and part[ 0 ].isdigit():\n",
    "            break\n",
    "        prefix_parts.append( part )\n",
    "\n",
    "    # Join the parts back together with underscores.\n",
    "    return '_'.join( prefix_parts )\n",
    "\n",
    "\n",
    "extract_prefix( \"run-CPG_augm_large_CPG_augm_large_undirected_anchored_v1_2024-12-30T09-34-tag-batch_acc.csv\" )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ec870d92ed5dae9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_runs_dir = \"./model_runs/batch/\"\n",
    "train_runs_dir = \"./model_runs/train/\"\n",
    "test_runs_dir = \"./model_runs/test/\"\n",
    "\n",
    "BATCH_KEY = \"batch\"\n",
    "TRAIN_KEY = \"train\"\n",
    "TEST_KEY = \"test\"\n",
    "LOSS_KEY = \"loss\"\n",
    "ACC_KEY = \"acc\"\n",
    "ROC_KEY = \"roc\"\n",
    "\n",
    "KEY_MAPPING = {\n",
    "    BATCH_KEY: \"Train Batch\",\n",
    "    TRAIN_KEY: \"Train Epoch\",\n",
    "    TEST_KEY: \"Test Epoch\",\n",
    "    f\"{BATCH_KEY}_step\": \"Batch\",\n",
    "    f\"{TRAIN_KEY}_step\": \"Epoch\",\n",
    "    f\"{TEST_KEY}_step\": \"Epoch\",\n",
    "    LOSS_KEY: \"Loss\",\n",
    "    ACC_KEY: \"Accuracy\",\n",
    "    ROC_KEY: \"ROC AUC\",\n",
    "    1: \"higher is better\",\n",
    "    -1: \"lower is better\"\n",
    "}\n",
    "\n",
    "SCALAR_TARGET: dict[ str, int ] = {\n",
    "    LOSS_KEY: -1,\n",
    "    ACC_KEY: 1,\n",
    "    ROC_KEY: 1\n",
    "}\n",
    "\n",
    "dfs: dict[ str, dict[ str, dict[ str, pd.DataFrame ] ] ] = {\n",
    "    BATCH_KEY: { LOSS_KEY: { }, ACC_KEY: { } },\n",
    "    TRAIN_KEY: { LOSS_KEY: { }, ACC_KEY: { }, ROC_KEY: { } },\n",
    "    TEST_KEY: { LOSS_KEY: { }, ACC_KEY: { }, ROC_KEY: { } },\n",
    "}\n",
    "\n",
    "for run_dir in [ batch_runs_dir, train_runs_dir, test_runs_dir ]:\n",
    "    for run_file in io_utils.get_filenames_in_dir( run_dir ):\n",
    "        for run in dfs.keys():\n",
    "            if run in run_file:\n",
    "                run_dfs = dfs[ run ]\n",
    "                for scalar in run_dfs.keys():\n",
    "                    if run_file.endswith( f\"{scalar}.csv\" ):\n",
    "                        run_name = extract_prefix( run_file )\n",
    "                        print( f\"Add df {run} {scalar}: {run_name}\" )\n",
    "                        run_df = pd.read_csv( f\"{run_dir}{run_file}\" )\n",
    "                        run_dfs[ scalar ][ extract_prefix( run_name ) ] = run_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff9eb523ec95a982"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list( dfs[ BATCH_KEY ][ LOSS_KEY ].values() )[ 0 ]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0f2d556993145bc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "STEP_COL = \"Step\"\n",
    "VALUE_COL = \"Value\"\n",
    "\n",
    "\n",
    "def plot_fill_between( dfs: dict, run: str, scalar: str ):\n",
    "    run_dfs = dfs[ run ][ scalar ].values()\n",
    "\n",
    "    if len( run_dfs ) < 2:\n",
    "        return\n",
    "\n",
    "    # Determine the minimum number of rows across all dfs to align the steps.\n",
    "    min_length = min( len( df ) for df in run_dfs )\n",
    "    trimmed_dfs = [ df.iloc[ :min_length ].copy() for df in run_dfs ]\n",
    "\n",
    "    # Assume that the steps are aligned across dataframes.\n",
    "    steps = trimmed_dfs[ 0 ][ STEP_COL ].values\n",
    "\n",
    "    # Stack the 'Value' arrays from each dataframe for element-wise operations.\n",
    "    values = np.array( [ df[ VALUE_COL ].values for df in trimmed_dfs ] )\n",
    "\n",
    "    # Calculate the overall min, max and average for each step.\n",
    "    average = np.mean( values, axis=0 )\n",
    "    lower_bound = np.min( values, axis=0 )\n",
    "    upper_bound = np.max( values, axis=0 )\n",
    "\n",
    "    # Identify best run\n",
    "    final_values = [ df[ VALUE_COL ].iloc[ -1 ] for df in trimmed_dfs ]\n",
    "    if SCALAR_TARGET[ scalar ] < 0:\n",
    "        # Select the dataframe with the lowest final value.\n",
    "        best_run_idx = np.argmin( final_values )\n",
    "    else:\n",
    "        # Select the dataframe with the highest final value.\n",
    "        best_run_idx = np.argmax( final_values )\n",
    "    best_run = trimmed_dfs[ best_run_idx ][ VALUE_COL ].values\n",
    "\n",
    "    # Create the plot.\n",
    "    plt.figure( figsize=(10, 6) )\n",
    "\n",
    "    # Fill the area between the min and max values.\n",
    "    plt.fill_between( steps, lower_bound, upper_bound, color=ColorScheme.PRIMARY_LIGHT, alpha=0.5,\n",
    "                      label=f\"Min/Max\" )\n",
    "\n",
    "    # Plot the average line.\n",
    "    plt.plot( steps, average, color=ColorScheme.PRIMARY, linewidth=1, label=f\"Avg.\" )\n",
    "\n",
    "    # Plot best run.\n",
    "    plt.plot( steps, best_run, color=ColorScheme.SECONDARY, linewidth=2, label=f\"Best\" )\n",
    "\n",
    "    # Configure the plot.\n",
    "    plt.xlabel( KEY_MAPPING[ run ] )\n",
    "    plt.ylabel( f\"{KEY_MAPPING[ scalar ]} ({KEY_MAPPING[ SCALAR_TARGET[ scalar ] ]})\" )\n",
    "    #plt.title( f\"{run} {scalar}\" )\n",
    "    plt.legend()\n",
    "    plt.grid( True )\n",
    "\n",
    "    plt.savefig( f\"plots/model_{run}_{scalar}\", bbox_inches='tight', pad_inches=0.1 )\n",
    "\n",
    "\n",
    "plot_fill_between( dfs, BATCH_KEY, LOSS_KEY )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9549e86b1f0b6b73"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for run in dfs.keys():\n",
    "    for scalar in dfs[ run ].keys():\n",
    "        plot_fill_between( dfs, run, scalar )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4dc3c0a24cf870f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3108144f5f1d41eb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
