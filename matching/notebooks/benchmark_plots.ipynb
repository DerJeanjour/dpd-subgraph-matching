{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matching.glema.common.utils.plot_utils import ColorScheme"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9223a04bfdf7fa95"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size_summary_file = \"./generation_meta/dpdf/size_summary.csv\"\n",
    "benchmark_file = \"./generation_meta/dpdf/benchmark.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def transform_project( x: str, prefix=\"dpdf\" ):\n",
    "    x = x.lower()\n",
    "    x = x.replace( \" \", \"_\" )\n",
    "    x = x.replace( \".\", \"\" )\n",
    "    return f\"{prefix}-{x}\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85c25776d0c4ccb0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_sizes = pd.read_csv( size_summary_file )\n",
    "df_sizes[ 'project' ] = df_sizes[ 'project' ].apply( transform_project )\n",
    "df_benchmarks = pd.read_csv( benchmark_file )\n",
    "df_benchmarks.rename( columns={ \"name\": \"project\" }, inplace=True )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce64c7259a159b46"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_benchmarks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d9dc42334e82a99"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_sizes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f7264d78d793f80"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "process_groups: dict[ str, list[ str ] ] = {\n",
    "    \"Fetching\": [\n",
    "        \"LoadPatternFileModule\",\n",
    "        \"ReadPatternsModule\",\n",
    "        \"AttachPatternsToContext\",\n",
    "        \"LoadDatasetFileModule\"\n",
    "    ],\n",
    "    \"Translating\": [\n",
    "        \"GenerateCpgModule\",\n",
    "        \"TranslationToGraphModule\"\n",
    "    ],\n",
    "    \"Processing\": [\n",
    "        \"RemoveBlacklistElementsModule\",\n",
    "        \"FilterInternalScopeModule\",\n",
    "        \"PropagateRecordScopeModule\",\n",
    "        \"ComputeRecordPathsModule\",\n",
    "        \"ComputeRecordInteractionsModule\",\n",
    "        \"CpgFilterEdgesModule\"\n",
    "    ],\n",
    "    \"Persisting\": [\n",
    "        \"MarkPatternsModule\",\n",
    "        \"PersistCpgModule\"\n",
    "    ]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bdae10f0bbb6cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a mapping from each process name to its group\n",
    "process_to_group = { }\n",
    "for group, processes in process_groups.items():\n",
    "    for proc in processes:\n",
    "        process_to_group[ proc ] = group\n",
    "\n",
    "# Map process names in df to their respective group\n",
    "df_benchmarks[ 'process_group' ] = df_benchmarks[ 'process_name' ].map( process_to_group )\n",
    "\n",
    "# Convert process_time_sec to a numeric type (in case it's read as a string)\n",
    "df_benchmarks[ 'process_time_sec' ] = pd.to_numeric( df_benchmarks[ 'process_time_sec' ], errors='coerce' )\n",
    "\n",
    "# Group by \"name\" and \"group\", summing the process_time_sec, then unstack so each group is a column\n",
    "df = df_benchmarks.groupby( [ 'project', 'process_group' ] )[ 'process_time_sec' ].sum().unstack(\n",
    "    fill_value=0 ).reset_index()\n",
    "group_cols = list( process_groups.keys() )  # ['fetching', 'translating', 'processing', 'persisting']\n",
    "df = df[ (df[ group_cols ] != 0).all( axis=1 ) ]\n",
    "\n",
    "df = pd.merge( df, df_sizes, on='project' )\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad94abcc57dfc449"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "custom_colors = [ ColorScheme.PRIMARY, ColorScheme.PRIMARY_LIGHT, ColorScheme.SECONDARY, ColorScheme.SECONDARY_LIGHT ]\n",
    "\n",
    "# Define the group order\n",
    "groups = process_groups.keys()\n",
    "\n",
    "# Prepare data for boxplot: a list of series corresponding to each group\n",
    "data = [ df[ group ].dropna() for group in groups ]\n",
    "\n",
    "# Create the boxplot with a log scale on the y-axis\n",
    "fig, ax = plt.subplots( figsize=(10, 6) )\n",
    "bp = ax.boxplot( data,\n",
    "                 patch_artist=True,\n",
    "                 tick_labels=groups,\n",
    "                 showfliers=False,\n",
    "                 medianprops=dict( color=ColorScheme.HIGHLIGHT, linewidth=2 ),\n",
    "                 widths=0.8 )\n",
    "\n",
    "# Apply the custom colors to each box\n",
    "for patch, color in zip( bp[ 'boxes' ], custom_colors ):\n",
    "    patch.set_facecolor( color )\n",
    "\n",
    "# Set y-axis to log scale\n",
    "ax.set_yscale( 'log' )\n",
    "\n",
    "# Compute the global maximum across all groups\n",
    "all_data = pd.concat( data )\n",
    "global_max = all_data.max()\n",
    "\n",
    "# Manually set the top limit to 30% above the global max\n",
    "# (Adjust as needed if your data is very spread out)\n",
    "ax.set_ylim( top=global_max * 1.3 * 4 )\n",
    "\n",
    "# Add grid lines on the y-axis to act as a scale line\n",
    "ax.yaxis.grid( True, which='both', linewidth=0.2 )\n",
    "\n",
    "# Calculate and annotate statistics for each group\n",
    "for i, group in enumerate( groups ):\n",
    "    group_data = df[ group ].dropna()\n",
    "    med_val = group_data.median()\n",
    "    std_val = group_data.std()\n",
    "    min_val = group_data.min()\n",
    "    max_val = group_data.max()\n",
    "\n",
    "    # Create annotation text\n",
    "    annotation_text = (f\"med: {med_val:.3f}\\n\"\n",
    "                       f\"std: {std_val:.3f}\\n\"\n",
    "                       f\"min: {min_val:.3f}\\n\"\n",
    "                       f\"max: {max_val:.3f}\")\n",
    "\n",
    "    # Position annotation: For log scale, multiply the max value by a factor\n",
    "    x_pos = i + 1\n",
    "    #y_pos = max_val * 1.05  # 10% above the max value\n",
    "    y_pos = 400\n",
    "    ax.text( x_pos, y_pos, annotation_text,\n",
    "             ha='center', va='bottom', fontsize=9,\n",
    "             bbox=dict( facecolor='white', alpha=0.5, edgecolor='gray' ) )\n",
    "\n",
    "ax.set_ylabel( \"Process Time in Sec (Log Scale)\" )\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "\n",
    "plt.savefig( \"plots/benchmark_groups\" )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c170822d014273e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "107f352c2a8126ad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "groups = list( process_groups.keys() )\n",
    "\n",
    "# Create 10 equal-width bins for the \"bytes\" column\n",
    "num_bins = 20\n",
    "df[ 'byte_interval' ] = pd.qcut( df[ 'bytes' ], q=num_bins )\n",
    "\n",
    "# Group by the byte interval and compute the average process times for each process group\n",
    "grouped = df.groupby( 'byte_interval' )[ groups ].median()\n",
    "\n",
    "normalized = grouped.copy()\n",
    "for col in normalized.columns:\n",
    "    min_val = normalized[ col ].min()\n",
    "    max_val = normalized[ col ].max()\n",
    "    # Avoid division by zero if all values are equal\n",
    "    if max_val - min_val > 0:\n",
    "        normalized[ col ] = (normalized[ col ] - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        normalized[ col ] = 0.0\n",
    "\n",
    "# Compute the midpoint for each byte interval to serve as the x-axis values.\n",
    "#mid_points = normalized.index.map( lambda interval: (interval.left + interval.right) / 2 )\n",
    "\n",
    "# Convert normalized values to percentages\n",
    "normalized_pct = normalized * 100\n",
    "# Create x-axis values as bin numbers 1, 2, ..., number of bins\n",
    "x = np.arange( 1, len( normalized_pct ) + 1 )\n",
    "\n",
    "# Extract values for each process group from the grouped DataFrame\n",
    "fetching = normalized_pct[ groups[ 0 ] ].values\n",
    "translating = normalized_pct[ groups[ 1 ] ].values\n",
    "processing = normalized_pct[ groups[ 2 ] ].values\n",
    "persisting = normalized_pct[ groups[ 3 ] ].values\n",
    "\n",
    "# Create the stackplot\n",
    "fig, ax = plt.subplots( figsize=(10, 6) )\n",
    "#ax.set_yscale( 'log' )\n",
    "\n",
    "ax.stackplot( x, fetching, translating, processing, persisting,\n",
    "              labels=groups, colors=custom_colors )\n",
    "\n",
    "ax.yaxis.grid( True, which='both', linewidth=0.2 )\n",
    "ax.set_xlabel( \"Source Code Memory Size Interval\" )\n",
    "ax.set_ylabel( \"Median Process Time (%)\" )\n",
    "ax.legend( loc='upper left' )\n",
    "\n",
    "# Set a specific number of x-axis ticks.\n",
    "desired_num_ticks = 20  # Change this to the number of ticks you want\n",
    "ticks = np.linspace( 1, num_bins, desired_num_ticks, dtype=int )\n",
    "ax.set_xticks( ticks )\n",
    "ax.set_xticklabels( ticks )\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig( \"plots/benchmark_scaling\" )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2a2a183c55c13f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "95d8221c60f03d82"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
