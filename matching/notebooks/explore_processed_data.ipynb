{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matching.glema.common.utils.arg_utils as arg_utils\n",
    "import matching.glema.common.utils.graph_utils as graph_utils\n",
    "import matching.glema.common.utils.io_utils as io_utils\n",
    "import matching.glema.common.utils.model_utils as model_utils\n",
    "import matching.glema.common.utils.plot_utils as plot_utils\n",
    "from matching.glema.common.dataset import BaseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "args = arg_utils.parse_args( use_default=True )\n",
    "\n",
    "args.dataset = \"dpdf\"\n",
    "args.directed = True\n",
    "args.anchored = True\n",
    "args.iso = True\n",
    "args.test_data = True"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3751665c755fade4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_name = model_utils.get_dataset_name( args )\n",
    "data_path = io_utils.get_abs_file_path( os.path.join( args.data_processed_dir, dataset_name ) )\n",
    "data_path"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e793caf6a913aeca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "key_file = os.path.join( data_path, args.test_keys if args.test_data else args.train_keys )\n",
    "with open( key_file, \"rb\" ) as fp:\n",
    "    keys = pickle.load( fp )\n",
    "print( f\"Number of total data points: {len( keys )}\" )\n",
    "iso_key_idxs = [ i for i, k in enumerate( keys ) if \"iso\" in k ]\n",
    "non_iso_key_idxs = [ i for i, k in enumerate( keys ) if \"non\" in k ]\n",
    "print( f\"Data point split total: iso [{len( iso_key_idxs )}] / noniso [{len( non_iso_key_idxs )}]\" )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ec4d2312481824a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "matching_colors = {\n",
    "    2: \"purple\",\n",
    "    1: \"green\",\n",
    "    0: \"grey\",\n",
    "    -1: \"red\"\n",
    "}\n",
    "\n",
    "\n",
    "def get_sample( dataset, sample_idx, relabel=True, normalize_d=-1 ):\n",
    "    sample_data = dataset.get_data( sample_idx )\n",
    "    query, source, mapping = sample_data\n",
    "    mapping = { qnid: snid for qnid, snid in mapping }\n",
    "    if relabel:\n",
    "        query = graph_utils.relabel_nodes( query, mapping )\n",
    "    if normalize_d > 0:\n",
    "        source, _ = graph_utils.normalize_graph( source, max_distance=6, force_directed=True )\n",
    "        query, _ = graph_utils.normalize_graph( query, max_distance=6, force_directed=True )\n",
    "    return source, query, mapping\n",
    "\n",
    "\n",
    "def is_iso( dataset, sample_idx ):\n",
    "    return \"iso\" in dataset.get_key( sample_idx )\n",
    "\n",
    "\n",
    "def get_colors( G ):\n",
    "    return [ \"purple\" if d[ \"anchor\" ] == 1 else \"grey\" for n, d in G.nodes( data=True ) ]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4492d3145053f5de"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "complexity_keys = model_utils.load_complexity_keys( args, train=not args.test_data )\n",
    "for (key, values) in complexity_keys.items():\n",
    "    print( f\"complexity {key}: {len( values )} samples\" )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "332b950406be9dc8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = BaseDataset( keys, args,\n",
    "                       k_start=1, k_keys=complexity_keys,\n",
    "                       max_size=10_000 )\n",
    "print( f\"Current complexity: {dataset.get_complexity_limit()}\" )\n",
    "dataset.remove_complexity_limit()\n",
    "\n",
    "iso_key_idxs = [ idx for idx in list( range( dataset.__len__() ) ) if is_iso( dataset, idx ) ]\n",
    "non_iso_key_idxs = [ idx for idx in list( range( dataset.__len__() ) ) if not is_iso( dataset, idx ) ]\n",
    "print( f\"Number of data points: {dataset.__len__()}\" )\n",
    "print( f\"Data point split: iso [{len( iso_key_idxs )}] / noniso [{len( non_iso_key_idxs )}]\" )\n",
    "\n",
    "iso_keys, non_iso_keys = dataset.get_key_split()\n",
    "print( f\"actual data points: iso [{len( iso_keys )}] / noniso [{len( non_iso_keys )}]\" )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df73a676ee4b193e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_idx = iso_key_idxs[ 0 ]\n",
    "source, query, _ = get_sample( dataset, sample_idx )\n",
    "print( dataset.__getitem__( sample_idx ) )\n",
    "\n",
    "combined, n_colors, e_colors = graph_utils.combine_graph( source, query, matching_colors=matching_colors )\n",
    "#combined, n_colors, e_colors = graph_utils.combine_normalized( source, query, matching_colors=matching_colors )\n",
    "\n",
    "plot_utils.plot_graph( title=\"source\", graph=source,\n",
    "                       nodeColors=get_colors( source ),\n",
    "                       nodeLabels=graph_utils.get_node_labels( source ) )\n",
    "plot_utils.plot_graph( title=\"query (iso)\", graph=query,\n",
    "                       nodeColors=get_colors( query ),\n",
    "                       nodeLabels=graph_utils.get_node_labels( query ) )\n",
    "plot_utils.plot_graph(\n",
    "    title=\"combined sample (iso)\", graph=combined,\n",
    "    nodeColors=n_colors, edgeColors=e_colors,\n",
    "    nodeLabels=graph_utils.get_node_labels( combined )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0e7441b1df5f9b3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_idx = non_iso_key_idxs[ 4 ]\n",
    "source, query, _ = get_sample( dataset, sample_idx )\n",
    "print( dataset.__getitem__( sample_idx ) )\n",
    "\n",
    "combined, n_colors, e_colors = graph_utils.combine_graph( source, query, matching_colors=matching_colors )\n",
    "#combined, n_colors, e_colors = graph_utils.combine_normalized( source, query, matching_colors=matching_colors )\n",
    "\n",
    "plot_utils.plot_graph( title=\"source\", graph=source,\n",
    "                       nodeColors=get_colors( source ),\n",
    "                       nodeLabels=graph_utils.get_node_labels( source ) )\n",
    "plot_utils.plot_graph( title=\"query (non iso)\", graph=query,\n",
    "                       nodeColors=get_colors( query ),\n",
    "                       nodeLabels=graph_utils.get_node_labels( query ) )\n",
    "plot_utils.plot_graph(\n",
    "    title=\"combined sample (non iso)\", graph=combined,\n",
    "    nodeColors=n_colors, edgeColors=e_colors,\n",
    "    nodeLabels=graph_utils.get_node_labels( combined )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11493016c84af2a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sources_with_anchor = 0\n",
    "queries_with_anchor = 0\n",
    "iso_samples = 0\n",
    "non_iso_samples = 0\n",
    "iso_samples_with_same_anchor = 0\n",
    "non_iso_samples_with_same_anchor = 0\n",
    "iso_samples_with_bigger_query = 0\n",
    "non_iso_samples_with_bigger_query = 0\n",
    "\n",
    "sources_max_5 = 0\n",
    "sources_5_10 = 0\n",
    "sources_10_15 = 0\n",
    "sources_15_20 = 0\n",
    "sources_20_30 = 0\n",
    "sources_30_40 = 0\n",
    "sources_min_40 = 0\n",
    "\n",
    "queries_max_5 = 0\n",
    "queries_5_10 = 0\n",
    "queries_10_15 = 0\n",
    "queries_15_20 = 0\n",
    "queries_20_30 = 0\n",
    "queries_30_40 = 0\n",
    "queries_min_40 = 0\n",
    "\n",
    "iso_samples_are_iso = 0\n",
    "non_iso_samples_are_iso = 0\n",
    "measure_iso = False\n",
    "\n",
    "dataset_len = dataset.__len__()\n",
    "for sample_idx in tqdm( list( range( dataset_len ) ) ):\n",
    "\n",
    "    is_iso_sample = False\n",
    "    if is_iso( dataset, sample_idx ):\n",
    "        is_iso_sample = True\n",
    "        iso_samples += 1\n",
    "    else:\n",
    "        non_iso_samples += 1\n",
    "\n",
    "    source, query, mapping = get_sample( dataset, sample_idx, relabel=True )\n",
    "\n",
    "    source_anchor = graph_utils.get_anchor( source )\n",
    "    if source_anchor >= 0:\n",
    "        sources_with_anchor += 1\n",
    "\n",
    "    query_anchor = graph_utils.get_anchor( query )\n",
    "    if query_anchor >= 0:\n",
    "        queries_with_anchor += 1\n",
    "\n",
    "        if source_anchor == query_anchor:\n",
    "            if is_iso_sample:\n",
    "                iso_samples_with_same_anchor += 1\n",
    "            else:\n",
    "                non_iso_samples_with_same_anchor += 1\n",
    "\n",
    "    if query.number_of_nodes() > source.number_of_nodes():\n",
    "        if is_iso_sample:\n",
    "            iso_samples_with_bigger_query += 1\n",
    "        else:\n",
    "            non_iso_samples_with_bigger_query += 1\n",
    "\n",
    "    source_size = source.number_of_nodes()\n",
    "    if source_size <= 5:\n",
    "        sources_max_5 += 1\n",
    "    if 5 < source_size <= 10:\n",
    "        sources_5_10 += 1\n",
    "    if 10 < source_size <= 15:\n",
    "        sources_10_15 += 1\n",
    "    if 15 < source_size <= 20:\n",
    "        sources_15_20 += 1\n",
    "    if 20 < source_size <= 30:\n",
    "        sources_20_30 += 1\n",
    "    if 30 < source_size <= 40:\n",
    "        sources_30_40 += 1\n",
    "    if 40 < source_size:\n",
    "        sources_min_40 += 1\n",
    "\n",
    "    query_size = query.number_of_nodes()\n",
    "    if query_size <= 5:\n",
    "        queries_max_5 += 1\n",
    "    if 5 < query_size <= 10:\n",
    "        queries_5_10 += 1\n",
    "    if 10 < query_size <= 15:\n",
    "        queries_10_15 += 1\n",
    "    if 15 < query_size <= 20:\n",
    "        queries_15_20 += 1\n",
    "    if 20 < query_size <= 30:\n",
    "        queries_20_30 += 1\n",
    "    if 30 < query_size <= 40:\n",
    "        queries_30_40 += 1\n",
    "    if 40 < query_size:\n",
    "        queries_min_40 += 1\n",
    "\n",
    "    if measure_iso:\n",
    "        if graph_utils.is_iso_subgraph( source, query ):\n",
    "            if is_iso_sample:\n",
    "                iso_samples_are_iso += 1\n",
    "            else:\n",
    "                non_iso_samples_are_iso += 1\n",
    "\n",
    "print( f\"Sources with anchor: {sources_with_anchor}/{dataset_len}\" )\n",
    "print( f\"Queries with anchor: {queries_with_anchor}/{dataset_len}\" )\n",
    "print( f\"Iso samples with same anchor: {iso_samples_with_same_anchor}/{iso_samples}\" )\n",
    "print( f\"Non iso samples with same anchor: {non_iso_samples_with_same_anchor}/{non_iso_samples}\" )\n",
    "print( f\"Iso samples with bigger query: {iso_samples_with_bigger_query}/{iso_samples}\" )\n",
    "print( f\"Non iso samples with bigger query: {non_iso_samples_with_bigger_query}/{non_iso_samples}\" )\n",
    "\n",
    "print( f\"Source samples with nodes size smaller 5: {sources_max_5}\" )\n",
    "print( f\"Source samples with nodes size between 5-10: {sources_5_10}\" )\n",
    "print( f\"Source samples with nodes size between 10-15: {sources_10_15}\" )\n",
    "print( f\"Source samples with nodes size between 15-20: {sources_15_20}\" )\n",
    "print( f\"Source samples with nodes size between 20-30: {sources_20_30}\" )\n",
    "print( f\"Source samples with nodes size between 30-40: {sources_30_40}\" )\n",
    "print( f\"Source samples with nodes size greater 40: {sources_min_40}\" )\n",
    "\n",
    "print( f\"Queries samples with nodes size smaller 5: {queries_max_5}\" )\n",
    "print( f\"Queries samples with nodes size between 5-10: {queries_5_10}\" )\n",
    "print( f\"Queries samples with nodes size between 10-15: {queries_10_15}\" )\n",
    "print( f\"Queries samples with nodes size between 15-20: {queries_15_20}\" )\n",
    "print( f\"Queries samples with nodes size between 20-30: {queries_20_30}\" )\n",
    "print( f\"Queries samples with nodes size between 30-40: {queries_30_40}\" )\n",
    "print( f\"Queries samples with nodes size greater 40: {queries_min_40}\" )\n",
    "\n",
    "if measure_iso:\n",
    "    print( f\"Iso samples are iso: {iso_samples_are_iso}/{iso_samples}\" )\n",
    "    print( f\"Non iso samples are iso: {non_iso_samples_are_iso}/{non_iso_samples}\" )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a9aa04c776e76df"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "59f12afd627945e0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
