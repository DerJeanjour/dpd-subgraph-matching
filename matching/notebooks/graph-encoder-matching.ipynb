{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "\n",
    "from deepsnap.graph import Graph as DSGraph\n",
    "from deepsnap.batch import Batch"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "308d3a8b90a3a55a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "class Utils:\n",
    "    \n",
    "    def get_timestamp(self):\n",
    "        return datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M\")\n",
    "    \n",
    "    def get_device(self, force_cpu=True):\n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        use_mps = not use_cuda and torch.backends.mps.is_available()\n",
    "    \n",
    "        if not force_cpu and use_cuda:\n",
    "            device = torch.device(\"cuda\")\n",
    "        elif not force_cpu and use_mps:\n",
    "            device = torch.device(\"mps\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "    \n",
    "        return device\n",
    "\n",
    "\n",
    "    def generate_graph(self, size: int):\n",
    "        return nx.binomial_graph(size, p=0.05, directed=False)\n",
    "    \n",
    "    def sample_neigh(self, graphs, size):\n",
    "        ps = np.array([len(g) for g in graphs], dtype=float)\n",
    "        ps /= np.sum(ps)\n",
    "        dist = stats.rv_discrete(values=(np.arange(len(graphs)), ps))\n",
    "        while True:\n",
    "            idx = dist.rvs()\n",
    "            #graph = random.choice(graphs)\n",
    "            graph = graphs[idx]\n",
    "            start_node = random.choice(list(graph.nodes))\n",
    "            neigh = [start_node]\n",
    "            frontier = list(set(graph.neighbors(start_node)) - set(neigh))\n",
    "            visited = set([start_node])\n",
    "            while len(neigh) < size and frontier:\n",
    "                new_node = random.choice(list(frontier))\n",
    "                assert new_node not in neigh\n",
    "                neigh.append(new_node)\n",
    "                visited.add(new_node)\n",
    "                frontier += list(graph.neighbors(new_node))\n",
    "                frontier = [x for x in frontier if x not in visited]\n",
    "            if len(neigh) == size:\n",
    "                return graph, neigh\n",
    "    \n",
    "    def batch_nx_graphs(self, graphs, anchors=None):\n",
    "\n",
    "        #augmenter = feature_preprocess.FeatureAugment()\n",
    "        \n",
    "        if anchors is not None:\n",
    "            for anchor, g in zip(anchors, graphs):\n",
    "                for v in g.nodes:\n",
    "                    g.nodes[v][\"node_feature\"] = torch.tensor([float(v == anchor)])\n",
    "    \n",
    "        batch = Batch.from_data_list([DSGraph(g) for g in graphs])\n",
    "        #batch = augmenter.augment(batch)\n",
    "        batch = batch.to(self.get_device())\n",
    "        return batch\n",
    "    \n",
    "utils = Utils()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4affdac9175a4337",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#import numpy as np\n",
    "import random\n",
    "\n",
    "SEED = 127\n",
    "np.random.seed(SEED)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86ecad81479f21d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_graph(G, with_label=False):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    node_size = 200\n",
    "    if not with_label:\n",
    "        node_size = node_size * 0.1\n",
    "    nx.draw(G,\n",
    "            pos=nx.spring_layout(G, seed=42),\n",
    "            with_labels=with_label,\n",
    "            node_color=\"skyblue\",\n",
    "            node_size=node_size,\n",
    "            font_size=6,\n",
    "            font_color=\"black\",\n",
    "            width=0.5,\n",
    "            edge_color=\"gray\")\n",
    "    plt.title(f\"Graph with {len(G.nodes)} nodes and {len(G.edges)} edges\", size=10)\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31d9ac12b6512fad",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "n = 1000\n",
    "G = nx.binomial_graph(100, p=0.05, directed=False, seed=SEED)\n",
    "plot_graph(G)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def random_subgraph(G, k):\n",
    "    np.random.seed(SEED)\n",
    "    random_node = np.random.choice(list(G.nodes()))\n",
    "    return nx.ego_graph(G, random_node, radius=k)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7159d6431efc625",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "k = 2\n",
    "G_target = random_subgraph(G, 2)\n",
    "plot_graph(G_target, with_label=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "deb2fcadbd789a51",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "G_query_pos = random_subgraph(G_target, 1)\n",
    "plot_graph(G_query_pos, with_label=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9e2e187364e3717",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import copy\n",
    "\n",
    "def inject_edge_errors(G, e: int = 1):\n",
    "    np.random.seed(SEED)\n",
    "    G_error = copy.deepcopy(G)\n",
    "\n",
    "    for _ in range(e):\n",
    "        modification_type = np.random.choice(['add', 'delete'])\n",
    "        if modification_type == 'delete':\n",
    "            if G_error.number_of_edges() > 0:\n",
    "                idx_remove = np.random.randint(0, len(G_error.edges()))\n",
    "                edge_to_remove = list(G_error.edges())[idx_remove]\n",
    "                G_error.remove_edge(*edge_to_remove)\n",
    "                print(f\"Deleted edge: {edge_to_remove}\")\n",
    "        elif modification_type == 'add':\n",
    "            possible_edges = list(nx.non_edges(G_error))  # Edges that do not currently exist\n",
    "            if possible_edges:\n",
    "                idx_add = np.random.randint(0, len(possible_edges))\n",
    "                edge_to_add = possible_edges[idx_add]\n",
    "                G_error.add_edge(*edge_to_add)\n",
    "                print(f\"Added new edge: {edge_to_add}\")\n",
    "\n",
    "    return G_error"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3544ea473742189",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "G_query_neg = inject_edge_errors(G_query_pos)\n",
    "plot_graph(G_query_neg, with_label=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af624450c4eacca7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "\n",
    "from deepsnap.batch import Batch\n",
    "from deepsnap.dataset import GraphDataset\n",
    "from torch.utils.data import DataLoader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd2ffaa3264e5ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "class Args:\n",
    "    conv_type = 'graph'\n",
    "    method_type = 'order'\n",
    "    dataset = 'syn'\n",
    "    n_layers = 4\n",
    "    batch_size = 64\n",
    "    hidden_dim = 64\n",
    "    skip = \"learnable\"\n",
    "    dropout = 0.0\n",
    "    n_batches = 100000\n",
    "    opt = 'adam'\n",
    "    opt_scheduler = 'none'\n",
    "    opt_restart = 100\n",
    "    weight_decay = 0.0\n",
    "    lr = 1e-4\n",
    "    margin = 0.1\n",
    "    test_set = ''\n",
    "    eval_interval = 1000\n",
    "    n_workers = 4\n",
    "    model_path = \"ckpt/model.pt\"\n",
    "    tag = ''\n",
    "    val_size = 2048\n",
    "    node_anchored = True\n",
    "    test = False"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "371bbec51a6cfeca",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "class SkipLastGNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, args: Args):\n",
    "        super(SkipLastGNN, self).__init__()\n",
    "        self.dropout = args.dropout\n",
    "        self.n_layers = args.n_layers\n",
    "\n",
    "        self.feat_preprocess = None  # TODO check for reason\n",
    "\n",
    "        self.pre_mp = nn.Sequential(nn.Linear(input_dim, hidden_dim))\n",
    "\n",
    "        conv_model = self.build_conv_model(args.conv_type, 1)\n",
    "        self.convs = nn.ModuleList()\n",
    "\n",
    "        if args.skip == 'learnable':  # TODO check for reason\n",
    "            self.learnable_skip = nn.Parameter(torch.ones(self.n_layers, self.n_layers))\n",
    "\n",
    "        for layer in range(args.n_layers):\n",
    "            if args.skip == 'all' or args.skip == 'learnable':\n",
    "                hidden_input_dim = hidden_dim * (layer + 1)\n",
    "            else:\n",
    "                hidden_input_dim = hidden_dim\n",
    "\n",
    "            self.convs.append(conv_model(hidden_input_dim, hidden_dim))\n",
    "\n",
    "        post_input_dim = hidden_dim * (args.n_layers + 1)\n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(post_input_dim, hidden_dim), nn.Dropout(args.dropout),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 256), nn.ReLU(),\n",
    "            nn.Linear(256, hidden_dim))\n",
    "\n",
    "        self.skip = args.skip\n",
    "        self.conv_type = args.conv_type\n",
    "\n",
    "    def build_conv_model(self, model_type, n_inner_layers):\n",
    "        if model_type == \"GCN\":\n",
    "            return pyg_nn.GCNConv\n",
    "        elif model_type == \"graph\":\n",
    "            return pyg_nn.GraphConv\n",
    "        elif model_type == \"GAT\":\n",
    "            return pyg_nn.GATConv\n",
    "        else:\n",
    "            print(\"unrecognized model type\")\n",
    "\n",
    "    def forward(self, data):\n",
    "        if self.feat_preprocess is not None:\n",
    "            if not hasattr(data, \"preprocessed\"):\n",
    "                data = self.feat_preprocess(data)\n",
    "                data.preprocessed = True\n",
    "        x, edge_index, batch = data.node_feature, data.edge_index, data.batch\n",
    "        x = self.pre_mp(x)\n",
    "\n",
    "        all_emb = x.unsqueeze(1)\n",
    "        emb = x\n",
    "        for i in range(len(self.convs)):\n",
    "            if self.skip == 'learnable':\n",
    "                skip_vals = self.learnable_skip[i, :i + 1].unsqueeze(0).unsqueeze(-1)\n",
    "                curr_emb = all_emb * torch.sigmoid(skip_vals)\n",
    "                curr_emb = curr_emb.view(x.size(0), -1)\n",
    "                x = self.convs[i](curr_emb, edge_index)\n",
    "            elif self.skip == 'all':\n",
    "                x = self.convs[i](emb, edge_index)\n",
    "            else:\n",
    "                x = self.convs[i](x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            emb = torch.cat((emb, x), 1)\n",
    "            if self.skip == 'learnable':\n",
    "                all_emb = torch.cat((all_emb, x.unsqueeze(1)), 1)\n",
    "\n",
    "        emb = pyg_nn.global_add_pool(emb, batch)\n",
    "        emb = self.post_mp(emb)\n",
    "        return emb\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        return F.nll_loss(pred, label)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b221d8827ff45d32",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "class OrderEmbedder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, args: Args):\n",
    "        super(OrderEmbedder, self).__init__()\n",
    "        self.emb_model = SkipLastGNN(input_dim, hidden_dim, hidden_dim, args)\n",
    "        self.margin = args.margin\n",
    "        self.use_intersection = False\n",
    "\n",
    "        self.clf_model = nn.Sequential(nn.Linear(1, 2), nn.LogSoftmax(dim=-1))\n",
    "\n",
    "    def forward(self, emb_as, emb_bs):\n",
    "        return emb_as, emb_bs\n",
    "\n",
    "    def predict(self, pred):\n",
    "        \"\"\"Predict if b is a subgraph of a (batched), where emb_as, emb_bs = pred.\n",
    "\n",
    "        pred: list (emb_as, emb_bs) of embeddings of graph pairs\n",
    "\n",
    "        Returns: list of bools (whether a is subgraph of b in the pair)\n",
    "        \"\"\"\n",
    "        emb_as, emb_bs = pred\n",
    "        e = torch.sum(torch.max(torch.zeros_like(emb_as, device=emb_as.device), emb_bs - emb_as) ** 2, dim=1)\n",
    "        return e\n",
    "\n",
    "    def criterion(self, pred, intersect_embs, labels):\n",
    "        \"\"\"Loss function for order emb.\n",
    "        The e term is the amount of violation (if b is a subgraph of a).\n",
    "        For positive examples, the e term is minimized (close to 0); \n",
    "        for negative examples, the e term is trained to be at least greater than self.margin.\n",
    "\n",
    "        pred: lists of embeddings outputted by forward\n",
    "        intersect_embs: not used\n",
    "        labels: subgraph labels for each entry in pred\n",
    "        \"\"\"\n",
    "        emb_as, emb_bs = pred\n",
    "        e = torch.sum(torch.max(torch.zeros_like(emb_as, device=utils.get_device()), emb_bs - emb_as) ** 2, dim=1)\n",
    "\n",
    "        margin = self.margin\n",
    "        e[labels == 0] = torch.max(torch.tensor(0.0, device=utils.get_device()), margin - e)[labels == 0]\n",
    "\n",
    "        relation_loss = torch.sum(e)\n",
    "\n",
    "        return relation_loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6d65179eede0af0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "import torchinfo\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59e80a6dc496fc5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def build_model(args: Args) -> nn.Module:\n",
    "    model = OrderEmbedder(1, args.hidden_dim, args)\n",
    "    model.to(utils.get_device())\n",
    "    if args.test and args.model_path:\n",
    "        model.load_state_dict(torch.load(args.model_path, map_location=utils.get_device(), weights_only=False))\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fd93ab1e7e78e88",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def build_optimizer(model: nn.Module, args: Args) -> optim.Optimizer:\n",
    "    weight_decay = args.weight_decay\n",
    "    filter_fn = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    if args.opt == 'adam':\n",
    "        optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    return optimizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76ad778fb4434fcc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def get_dataset():\n",
    "    task = \"graph\"\n",
    "    dataset = []\n",
    "    for i in range(10):\n",
    "        dataset.append( utils.generate_graph( 100 ) )\n",
    "        \n",
    "    train_len = int(0.8 * len(dataset))\n",
    "    train, test = [], []\n",
    "    random.shuffle(dataset)\n",
    "    for i, graph in enumerate(dataset):\n",
    "        if i < train_len:\n",
    "            train.append(graph)\n",
    "        else:\n",
    "            test.append(graph)\n",
    "    return train, test, task"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f6ac94fa666a04e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def gen_data_loaders(size: int, batch_size: int):\n",
    "    loaders = [[batch_size]*(size // batch_size) for i in range(3)]\n",
    "    return loaders"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5236ad4c94706f48",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def gen_batch(dataset, a, b, c, train, node_anchored=True, filter_negs=False, max_size=15, min_size=5, batched=True ):\n",
    "    batch_size = a\n",
    "    train_set, test_set, task = dataset\n",
    "    graphs = train_set if train else test_set\n",
    "\n",
    "    # pos \n",
    "    pos_target, pos_query = [], []\n",
    "    pos_target_anchors, pos_query_anchors = [], []\n",
    "    for i in range(batch_size // 2):\n",
    "        # tree-pair\n",
    "        size = random.randint(min_size+1, max_size)\n",
    "        graph, a = utils.sample_neigh(graphs, size)\n",
    "        b = a[:random.randint(min_size, len(a) - 1)]\n",
    "        if node_anchored:\n",
    "            anchor = list(graph.nodes)[0]\n",
    "            pos_target_anchors.append(anchor)\n",
    "            pos_query_anchors.append(anchor)\n",
    "        neigh_target, neigh_query = graph.subgraph(a), graph.subgraph(b)\n",
    "        pos_target.append(neigh_target)\n",
    "        pos_query.append(neigh_query)\n",
    "\n",
    "    # neg \n",
    "    neg_target, neg_query = [], []\n",
    "    neg_target_anchors, neg_query_anchors = [], []\n",
    "    while len(neg_target) < batch_size // 2:\n",
    "        # tree-pair\n",
    "        size = random.randint(min_size+1, max_size)\n",
    "        graph_a, a = utils.sample_neigh(graphs, size)\n",
    "        graph_b, b = utils.sample_neigh(graphs, random.randint(min_size, size - 1))\n",
    "        if node_anchored:\n",
    "            neg_target_anchors.append(list(graph_a.nodes)[0])\n",
    "            neg_query_anchors.append(list(graph_b.nodes)[0])\n",
    "        neigh_target, neigh_query = graph_a.subgraph(a), graph_b.subgraph(b)\n",
    "        if filter_negs:\n",
    "            matcher = nx.algorithms.isomorphism.GraphMatcher(neigh_target, neigh_query)\n",
    "            if matcher.subgraph_is_isomorphic(): # a <= b (b is subgraph of a)\n",
    "                continue\n",
    "        neg_target.append(neigh_target)\n",
    "        neg_query.append(neigh_query)\n",
    "        \n",
    "    if not batched:\n",
    "        return pos_target, pos_query, neg_target, neg_query\n",
    "\n",
    "    # to batches \n",
    "    pos_target = utils.batch_nx_graphs(pos_target, anchors=pos_target_anchors if node_anchored else None)\n",
    "    pos_query = utils.batch_nx_graphs(pos_query, anchors=pos_query_anchors if node_anchored else None)\n",
    "    neg_target = utils.batch_nx_graphs(neg_target, anchors=neg_target_anchors if node_anchored else None)\n",
    "    neg_query = utils.batch_nx_graphs(neg_query, anchors=neg_query_anchors if node_anchored else None)\n",
    "    return pos_target, pos_query, neg_target, neg_query"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a15f635c917a8a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "args = Args()\n",
    "dataset = get_dataset()\n",
    "loaders = gen_data_loaders(args.eval_interval * args.batch_size, args.batch_size)\n",
    "for batch_target, batch_neg_target, batch_neg_query in zip(*loaders):\n",
    "    \n",
    "    print(batch_target, batch_neg_target, batch_neg_query)\n",
    "    \n",
    "    pos_target, pos_query, neg_target, neg_query = gen_batch( dataset, batch_target, batch_neg_target, batch_neg_query, True )\n",
    "    print(pos_target)\n",
    "    print(pos_query)\n",
    "    print(neg_target)\n",
    "    print(neg_query)\n",
    "    \n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f0c227d15b01574",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def train(model: nn.Module, dataset, args: Args):\n",
    "    \n",
    "    optimizer = build_optimizer(model, args)\n",
    "    clf_opt = optim.Adam(model.clf_model.parameters(), lr=args.lr)\n",
    "    \n",
    "    loaders = gen_data_loaders(args.eval_interval * args.batch_size, args.batch_size)\n",
    "    batch_count = len(loaders[0])\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    current_batch = 0\n",
    "    for batch_target, batch_neg_target, batch_neg_query in zip(*loaders):\n",
    "     \n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        pos_target, pos_query, neg_target, neg_query = gen_batch( dataset, batch_target, batch_neg_target, batch_neg_query, True )\n",
    "        emb_pos_target, emb_pos_query = model.emb_model(pos_target), model.emb_model(pos_query)\n",
    "        emb_neg_target, emb_neg_query = model.emb_model(neg_target), model.emb_model(neg_query)\n",
    "        \n",
    "        emb_targets = torch.cat((emb_pos_target, emb_neg_target), dim=0)\n",
    "        emb_queries = torch.cat((emb_pos_query, emb_neg_query), dim=0)\n",
    "        labels = torch.tensor([1]*pos_target.num_graphs + [0]*neg_target.num_graphs).to(utils.get_device())\n",
    "        \n",
    "        pred = model(emb_targets, emb_queries)\n",
    "        loss = model.criterion(pred, None, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = model.predict(pred)\n",
    "            \n",
    "        model.clf_model.zero_grad()\n",
    "        pred = model.clf_model(pred.unsqueeze(1))\n",
    "        criterion = nn.NLLLoss()\n",
    "        clf_loss = criterion(pred, labels)\n",
    "        clf_loss.backward()\n",
    "        clf_opt.step()\n",
    "            \n",
    "        pred = pred.argmax(dim=-1)\n",
    "        acc = torch.mean((pred == labels).type(torch.float))\n",
    "        train_loss += loss.item()\n",
    "        train_acc += acc.item()\n",
    "        \n",
    "        current_batch += 1\n",
    "        if current_batch % 10 == 0:\n",
    "            print( f\"Finished batch {current_batch}/{batch_count}: loss: {loss.item():.4f} / accuracy: {acc.item():.4f}\" )\n",
    "        \n",
    "    return train_loss / batch_count, train_acc / batch_count"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81db8de2e55a6e6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import roc_auc_score, confusion_matrix, average_precision_score\n",
    "\n",
    "def validate(args: Args, model: nn.Module, dataset):\n",
    "    print( f\"Starting validation ...\" )\n",
    "    \n",
    "    loaders = gen_data_loaders(args.val_size, args.batch_size)\n",
    "    test_pts = []\n",
    "    for batch_target, batch_neg_target, batch_neg_query in zip(*loaders):\n",
    "        test_pts.append(gen_batch( dataset, batch_target, batch_neg_target, batch_neg_query, True ))\n",
    "    \n",
    "    model.eval()\n",
    "    all_raw_preds, all_preds, all_labels = [], [], []\n",
    "    for pos_a, pos_b, neg_a, neg_b in test_pts:\n",
    "        if pos_a:\n",
    "            pos_a = pos_a.to(utils.get_device())\n",
    "            pos_b = pos_b.to(utils.get_device())\n",
    "        neg_a = neg_a.to(utils.get_device())\n",
    "        neg_b = neg_b.to(utils.get_device())\n",
    "        labels = torch.tensor([1]*(pos_a.num_graphs if pos_a else 0) + [0]*neg_a.num_graphs).to(utils.get_device())\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            emb_neg_a, emb_neg_b = (model.emb_model(neg_a), model.emb_model(neg_b))\n",
    "            \n",
    "            if pos_a:\n",
    "                emb_pos_a, emb_pos_b = (model.emb_model(pos_a),model.emb_model(pos_b))\n",
    "                emb_as = torch.cat((emb_pos_a, emb_neg_a), dim=0)\n",
    "                emb_bs = torch.cat((emb_pos_b, emb_neg_b), dim=0)\n",
    "            else:\n",
    "                emb_as, emb_bs = emb_neg_a, emb_neg_b\n",
    "                \n",
    "            pred = model(emb_as, emb_bs)\n",
    "            raw_pred = model.predict(pred)\n",
    "\n",
    "            pred = model.clf_model(raw_pred.unsqueeze(1)).argmax(dim=-1)\n",
    "            raw_pred *= -1\n",
    "            \n",
    "        all_raw_preds.append(raw_pred)\n",
    "        all_preds.append(pred)\n",
    "        all_labels.append(labels)\n",
    "        \n",
    "    pred = torch.cat(all_preds, dim=-1)\n",
    "    labels = torch.cat(all_labels, dim=-1)\n",
    "    raw_pred = torch.cat(all_raw_preds, dim=-1)\n",
    "    acc = torch.mean((pred == labels).type(torch.float))\n",
    "    prec = (torch.sum(pred * labels).item() / torch.sum(pred).item() if torch.sum(pred) > 0 else float(\"NaN\"))\n",
    "    recall = (torch.sum(pred * labels).item() / torch.sum(labels).item() if torch.sum(labels) > 0 else float(\"NaN\"))\n",
    "    labels = labels.detach().cpu().numpy()\n",
    "    raw_pred = raw_pred.detach().cpu().numpy()\n",
    "    pred = pred.detach().cpu().numpy()\n",
    "    auroc = roc_auc_score(labels, raw_pred)\n",
    "    avg_prec = average_precision_score(labels, raw_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, pred).ravel()\n",
    "\n",
    "    return acc, prec, recall, auroc, avg_prec, tn, fp, fn, tp"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81f4ef1d0dbfdb81",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "args = Args()\n",
    "if not os.path.exists(os.path.dirname(args.model_path)):\n",
    "    os.makedirs(os.path.dirname(args.model_path))\n",
    "    \n",
    "model = build_model(args)\n",
    "print(torchinfo.summary(model))\n",
    "dataset = get_dataset()\n",
    "\n",
    "record_keys = [\"conv_type\", \"n_layers\", \"hidden_dim\", \"margin\"]\n",
    "args_str = \".\".join([\"{}={}\".format(k, v) for k, v in sorted(vars(args).items()) if k in record_keys])\n",
    "logger = SummaryWriter(log_dir=f'runs/{args.conv_type}{args.n_layers}_{utils.get_timestamp()}', comment=args_str)\n",
    "\n",
    "if args.test:\n",
    "    print( \"starting test ...\" )\n",
    "    results = validate(args, model, dataset)\n",
    "    acc, prec, recall, auroc, avg_prec, tn, fp, fn, tp = results\n",
    "    print(\"Testing. Acc: {:.4f}. \"\n",
    "    \"P: {:.4f}. R: {:.4f}. AUROC: {:.4f}. AP: {:.4f}.\\n\"\n",
    "    \"TN: {}. FP: {}. FN: {}. TP: {}\".format(\n",
    "        acc, prec, recall, auroc, avg_prec,\n",
    "        tn, fp, fn, tp))\n",
    "else:\n",
    "    epochs = args.n_batches // args.eval_interval\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # train\n",
    "        print( f\"starting epoch {epoch}/{epochs} ...\" )\n",
    "        loss, acc = train(model, dataset, args)\n",
    "        logger.add_scalar('train/loss', loss, epoch)\n",
    "        logger.add_scalar('train/accuracy', acc, epoch)\n",
    "        print( f\"finished epoch {epoch}/{epochs}: loss: {loss:.4f} / accuracy {acc:.4f}\" )\n",
    "        \n",
    "        # validate\n",
    "        results = validate(args, model, dataset)\n",
    "        acc, prec, recall, auroc, avg_prec, tn, fp, fn, tp = results\n",
    "        print(\"Validation. Epoch {}. Acc: {:.4f}. \"\n",
    "        \"P: {:.4f}. R: {:.4f}. AUROC: {:.4f}. AP: {:.4f}.\\n\"\n",
    "        \"TN: {}. FP: {}. FN: {}. TP: {}\".format(epoch,\n",
    "            acc, prec, recall, auroc, avg_prec,\n",
    "            tn, fp, fn, tp))\n",
    "        logger.add_scalar(\"test/accuracy\", acc, epoch)\n",
    "        logger.add_scalar(\"test/precision\", prec, epoch)\n",
    "        logger.add_scalar(\"test/recall\", recall, epoch)\n",
    "        logger.add_scalar(\"test/auroc\", auroc, epoch)\n",
    "        logger.add_scalar(\"test/avg_prec\", avg_prec, epoch)\n",
    "        logger.add_scalar(\"test/TP\", tp, epoch)\n",
    "        logger.add_scalar(\"test/TN\", tn, epoch)\n",
    "        logger.add_scalar(\"test/FP\", fp, epoch)\n",
    "        logger.add_scalar(\"test/FN\", fn, epoch)\n",
    "        \n",
    "        torch.save(model.state_dict(), args.model_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd1ba71218cf6f61",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def train(model: nn.Module, dataset, args: Args, in_queue: mp.Queue, out_queue: mp.Queue):\n",
    "    \n",
    "    optimizer = build_optimizer(model, args)\n",
    "    clf_opt = optim.Adam(model.clf_model.parameters(), lr=args.lr)\n",
    "    \n",
    "    done = False\n",
    "    while not done:\n",
    "        \n",
    "        loaders = gen_data_loaders(args.eval_interval * args.batch_size, args.batch_size)\n",
    "        for batch_target, batch_neg_target, batch_neg_query in zip(*loaders):\n",
    "            \n",
    "            msg, _ = in_queue.get()\n",
    "            if msg == \"done\":\n",
    "                done = True\n",
    "                break\n",
    "         \n",
    "            model.train()\n",
    "            model.zero_grad()\n",
    "            pos_target, pos_query, neg_target, neg_query = gen_batch( dataset, batch_target, batch_neg_target, batch_neg_query, True )\n",
    "            emb_pos_target, emb_pos_query = model.emb_model(pos_target), model.emb_model(pos_query)\n",
    "            emb_neg_target, emb_neg_query = model.emb_model(neg_target), model.emb_model(neg_query)\n",
    "            \n",
    "            emb_targets = torch.cat((emb_pos_target, emb_neg_target), dim=0)\n",
    "            emb_queries = torch.cat((emb_pos_query, emb_neg_query), dim=0)\n",
    "            labels = torch.tensor([1]*pos_target.num_graphs + [0]*neg_target.num_graphs).to(utils.get_device())\n",
    "            \n",
    "            pred = model(emb_targets, emb_queries)\n",
    "            loss = model.criterion(pred, None, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                pred = model.predict(pred)\n",
    "                \n",
    "            model.clf_model.zero_grad()\n",
    "            pred = model.clf_model(pred.unsqueeze(1))\n",
    "            criterion = nn.NLLLoss()\n",
    "            clf_loss = criterion(pred, labels)\n",
    "            clf_loss.backward()\n",
    "            clf_opt.step()\n",
    "                \n",
    "            pred = pred.argmax(dim=-1)\n",
    "            acc = torch.mean((pred == labels).type(torch.float))\n",
    "            \n",
    "            out_queue.put((\"step\", (loss.item(), acc.item())))\n",
    "\n",
    "mp.set_start_method(\"spawn\", force=True)\n",
    "print(\"Starting {} workers\".format(args.n_workers))\n",
    "in_queue, out_queue = mp.Queue(), mp.Queue()\n",
    "\n",
    "args = Args()\n",
    "if not os.path.exists(os.path.dirname(args.model_path)):\n",
    "    os.makedirs(os.path.dirname(args.model_path))\n",
    "    \n",
    "model = build_model(args)\n",
    "print(torchinfo.summary(model))\n",
    "model.share_memory()\n",
    "dataset = get_dataset()\n",
    "\n",
    "record_keys = [\"conv_type\", \"n_layers\", \"hidden_dim\", \"margin\"]\n",
    "args_str = \".\".join([\"{}={}\".format(k, v) for k, v in sorted(vars(args).items()) if k in record_keys])\n",
    "logger = SummaryWriter(log_dir=f'runs/{args.conv_type}{args.n_layers}_{utils.get_timestamp()}', comment=args_str)\n",
    "\n",
    "if args.test:\n",
    "    print( \"starting test ...\" )\n",
    "    results = validate(args, model, dataset)\n",
    "    acc, prec, recall, auroc, avg_prec, tn, fp, fn, tp = results\n",
    "    print(\"Testing. Acc: {:.4f}. \"\n",
    "    \"P: {:.4f}. R: {:.4f}. AUROC: {:.4f}. AP: {:.4f}.\\n\"\n",
    "    \"TN: {}. FP: {}. FN: {}. TP: {}\".format(\n",
    "        acc, prec, recall, auroc, avg_prec,\n",
    "        tn, fp, fn, tp))\n",
    "else:\n",
    "    \n",
    "    workers = []\n",
    "    for i in range(args.n_workers):\n",
    "        worker = mp.Process(target=train, args=(model, dataset, args, in_queue, out_queue))\n",
    "        worker.start()\n",
    "        workers.append(worker)\n",
    "    \n",
    "    batch_n = 0\n",
    "    epochs = args.n_batches // args.eval_interval\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        \n",
    "        # train\n",
    "        for i in range(args.eval_interval):\n",
    "            in_queue.put((\"step\", None))\n",
    "        for i in range(args.eval_interval):\n",
    "            msg, params = out_queue.get()\n",
    "            loss, acc = params\n",
    "            epoch_loss += loss\n",
    "            epoch_acc = acc\n",
    "            print(\"Training Epoch {} [Batch {}] - Loss: {:.4f} / Accuracy: {:.4f}\".format(epoch, batch_n, loss, acc), end=\"               \\r\")\n",
    "            logger.add_scalar('train/loss', loss, epoch)\n",
    "            logger.add_scalar('train/accuracy', acc, epoch)\n",
    "            batch_n += 1\n",
    "            \n",
    "        print( f\"Finished Epoch {epoch}/{epochs}: Loss: {loss:.4f} / Accuracy: {acc:.4f}\" )\n",
    "            \n",
    "        # validate\n",
    "        results = validate(args, model, dataset)\n",
    "        acc, prec, recall, auroc, avg_prec, tn, fp, fn, tp = results\n",
    "        print(\"Validation Epoch {} - Acc: {:.4f}. \"\n",
    "        \"P: {:.4f}. R: {:.4f}. AUROC: {:.4f}. AP: {:.4f}.\\n\"\n",
    "        \"TN: {}. FP: {}. FN: {}. TP: {}\".format(epoch,\n",
    "            acc, prec, recall, auroc, avg_prec,\n",
    "            tn, fp, fn, tp))\n",
    "        logger.add_scalar(\"test/accuracy\", acc, epoch)\n",
    "        logger.add_scalar(\"test/precision\", prec, epoch)\n",
    "        logger.add_scalar(\"test/recall\", recall, epoch)\n",
    "        logger.add_scalar(\"test/auroc\", auroc, epoch)\n",
    "        logger.add_scalar(\"test/avg_prec\", avg_prec, epoch)\n",
    "        logger.add_scalar(\"test/TP\", tp, epoch)\n",
    "        logger.add_scalar(\"test/TN\", tn, epoch)\n",
    "        logger.add_scalar(\"test/FP\", fp, epoch)\n",
    "        logger.add_scalar(\"test/FN\", fn, epoch)\n",
    "        \n",
    "        torch.save(model.state_dict(), args.model_path)\n",
    "        \n",
    "    for i in range(args.n_workers):\n",
    "        in_queue.put((\"done\", None))\n",
    "    for worker in workers:\n",
    "        worker.join()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "663b76a014061597",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "test_args = Args()\n",
    "test_args.test = True\n",
    "\n",
    "test_model = build_model(test_args)\n",
    "test_dataset = get_dataset()\n",
    "test_dataset_example = test_dataset[1][0]\n",
    "\n",
    "plot_graph(test_dataset_example)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a520505c59eb3699",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "test_loaders = gen_data_loaders(args.val_size, args.batch_size)\n",
    "example_batch = None\n",
    "example_batch_graphs = None\n",
    "for batch_target, batch_neg_target, batch_neg_query in zip(*test_loaders):\n",
    "    example_batch = gen_batch( test_dataset, batch_target, batch_neg_target, batch_neg_query, True )\n",
    "    example_batch_graphs = gen_batch( test_dataset, batch_target, batch_neg_target, batch_neg_query, True, batched=False )\n",
    "    break\n",
    "   \n",
    "pos_target_graph, pos_query_graph, neg_target_graph, neg_query_graph = example_batch_graphs \n",
    "pos_target, pos_query, neg_target, neg_query = example_batch\n",
    "\n",
    "test_labels = torch.tensor([1]*(pos_target.num_graphs if neg_target else 0) + [0]*neg_target.num_graphs).to(utils.get_device())\n",
    "test_model.eval()\n",
    "with torch.no_grad():\n",
    "    \n",
    "    emb_pos_target, emb_pos_query = test_model.emb_model(pos_target), test_model.emb_model(pos_query)\n",
    "    emb_neg_target, emb_neg_query = test_model.emb_model(neg_target), test_model.emb_model(neg_query)\n",
    "    \n",
    "    emb_targets = torch.cat((emb_pos_target, emb_neg_target), dim=0)\n",
    "    emb_queries = torch.cat((emb_pos_query, emb_neg_query), dim=0)\n",
    "                \n",
    "    pred = model(emb_targets, emb_queries)\n",
    "    raw_pred = model.predict(pred)\n",
    "    \n",
    "    pred = model.clf_model(raw_pred.unsqueeze(1)).argmax(dim=-1)\n",
    "    raw_pred *= -1\n",
    "    \n",
    "print(pred)\n",
    "print(raw_pred)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64e6f6c14ef124b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "test_idx = 0"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b0cf98afe9d8b42",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "plot_graph(pos_target_graph[test_idx], with_label=True)\n",
    "plot_graph(pos_query_graph[test_idx], with_label=True)\n",
    "print(f\"Is query is subgraph - model: {pred[test_idx] == True} / actual  {test_labels[test_idx] == True}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae356a25bb7e76eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "plot_graph(neg_target_graph[test_idx], with_label=True)\n",
    "plot_graph(neg_query_graph[test_idx], with_label=True)\n",
    "print(f\"Is query is subgraph - model: {pred[len(pos_target_graph) + test_idx] == True} / actual: {test_labels[len(pos_target_graph) + test_idx] == True}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f3cfe5245d791f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "90dd38ef658872f6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
